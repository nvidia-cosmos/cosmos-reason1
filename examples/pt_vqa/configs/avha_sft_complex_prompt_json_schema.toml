# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

redis = "12800"


[train]
resume = true
epoch = 20
output_dir = "./outputs/avha_sft_vqa_complex_prompt_json_schema"
epsilon = 1e-6
optm_name = "AdamW"
optm_lr = 2e-6
optm_impl = "fused"
optm_weight_decay = 0.01
optm_betas = [ 0.9, 0.999,]
optm_warmup_steps = 20
optm_grad_norm_clip = 1.0
async_tp_enabled = false
compile = false
param_dtype = "bfloat16"
fsdp_reduce_dtype = "float32"
fsdp_offload = false
fsdp_reshard_after_forward = "default"
train_batch_per_replica = 16
sync_weight_interval = 1
enable_validation = true
validation_step = 30
validation_batch_per_replica = 2

[policy]
model_name_or_path = "nvidia/Cosmos-Reason1-7B"
model_max_length = 4096
model_gradient_checkpointing = true

[logging]
logger = ['console', 'wandb']
project_name = "cosmos_reason1_vqa"
experiment_name = "post_training/avha_sft_vqa_complex_prompt_json_schema"

[train.train_policy]
type = "sft"
enable_dataset_cache = false
dataloader_num_workers = 4
dataloader_prefetch_factor = 4
conversation_column_name = "conversations"
mini_batch = 4

[train.train_policy.dataset]
name = "/project/cosmos/jingyij/dataset/av_human_annotated/v0_1/train"

[train.ckpt]
enable_checkpoint = true
save_freq = 25
max_keep = 5
save_mode = "async"

[policy.parallelism]
n_init_replicas = 1
tp_size = 1
cp_size = 1
dp_shard_size = 8
pp_size = 1
dp_replicate_size = 1
cp_rotate_method = "allgather"
